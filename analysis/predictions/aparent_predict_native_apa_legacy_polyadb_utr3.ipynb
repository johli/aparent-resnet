{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.models import Sequential, Model, load_model\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "import scipy.sparse as sp\n",
    "import scipy.io as spio\n",
    "\n",
    "import isolearn.io as isoio\n",
    "import isolearn.keras as iso\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load sequence data\n",
    "\n",
    "df = pd.read_csv('../../../aparent/data/polyadb_features_pas_3_utr3.csv', sep='\\t')\n",
    "\n",
    "save_dict = np.load(\"../../../aparent/data/polyadb_features_pas_3_utr3_no_x.npz\")\n",
    "m, l = save_dict['m'], save_dict['l']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/jlinder2/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/jlinder2/anaconda3/envs/tensorflow/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jlinder2/anaconda3/envs/tensorflow/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n"
     ]
    }
   ],
   "source": [
    "#Load legacy APARENT model (lifted from theano)\n",
    "\n",
    "model_name = 'aparent_theano_legacy_30_31_34_pasaligned'\n",
    "\n",
    "save_dir = os.path.join(os.getcwd(), '../../../aparent/saved_models/legacy_models')\n",
    "model_path = os.path.join(save_dir, model_name + '.h5')\n",
    "\n",
    "aparent_model = load_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting for PAS #0...\n",
      "10720/10720 [==============================] - 12s 1ms/step\n",
      "Predicting for PAS #1...\n",
      "10720/10720 [==============================] - 12s 1ms/step\n",
      "Predicting for PAS #2...\n",
      "10720/10720 [==============================] - 12s 1ms/step\n",
      "Predicting for PAS #3...\n",
      "10720/10720 [==============================] - 12s 1ms/step\n",
      "Predicting for PAS #4...\n",
      "10720/10720 [==============================] - 12s 1ms/step\n",
      "Predicting for PAS #5...\n",
      "10720/10720 [==============================] - 12s 1ms/step\n",
      "Predicting for PAS #6...\n",
      "10720/10720 [==============================] - 18s 2ms/step\n",
      "Predicting for PAS #7...\n",
      "10720/10720 [==============================] - 12s 1ms/step\n",
      "Predicting for PAS #8...\n",
      "10720/10720 [==============================] - 12s 1ms/step\n",
      "Predicting for PAS #9...\n",
      "10720/10720 [==============================] - 12s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "#Score all sequences with APARENT (use sum of cuts to capture OR-like logic)\n",
    "\n",
    "max_n_pas = 10\n",
    "\n",
    "encoder = iso.OneHotEncoder(185)\n",
    "\n",
    "a = np.zeros((len(df), max_n_pas))\n",
    "a_all_cuts = np.zeros((len(df), max_n_pas))\n",
    "\n",
    "for k in range(max_n_pas) :\n",
    "    \n",
    "    print(\"Predicting for PAS #\" + str(k) + \"...\")\n",
    "    \n",
    "    df.loc[df['wide_seq_ext_' + str(k)].isnull(), 'wide_seq_ext_' + str(k)] = 'X' * 356\n",
    "    \n",
    "    onehots = np.concatenate([encoder.encode(row['wide_seq_ext_' + str(k)][175-50:175-50+185])[None, None, :, :] for _, row in df.iterrows()], axis=0)\n",
    "    \n",
    "    fake_lib = np.zeros((onehots.shape[0], 36))\n",
    "    fake_lib[:, 20] = 1.\n",
    "\n",
    "    fake_d = np.ones((onehots.shape[0], 1))\n",
    "    \n",
    "    #Pad\n",
    "    n_pad = 32 - onehots.shape[0] % 32 if onehots.shape[0] % 32 != 0 else 0\n",
    "\n",
    "    fake_lib = np.concatenate([fake_lib, np.zeros((n_pad, 36))], axis=0)\n",
    "    fake_d = np.concatenate([fake_d, np.zeros((n_pad, 1))], axis=0)\n",
    "    onehots = np.concatenate([onehots, np.zeros((n_pad, 1, 185, 4))], axis=0)\n",
    "    \n",
    "    pred_iso, pred_cuts = aparent_model.predict(x=[onehots, fake_lib, fake_d], batch_size=32, verbose=1)\n",
    "    \n",
    "    if n_pad > 0 :\n",
    "        pred_iso = pred_iso[:-n_pad, :]\n",
    "        pred_cuts = pred_cuts[:-n_pad, :]\n",
    "    \n",
    "    pred_iso = pred_iso[:, 0]\n",
    "    \n",
    "    isoform_start = 57\n",
    "    isoform_end = 107\n",
    "\n",
    "    pred_iso_from_cuts = np.sum(pred_cuts[:, isoform_start:isoform_end], axis=1)\n",
    "    score_from_iso = np.log(pred_iso / (1. - pred_iso))\n",
    "    score_from_cuts = np.log(pred_iso_from_cuts / (1. - pred_iso_from_cuts))\n",
    "    score = (score_from_iso + score_from_cuts) / 2.\n",
    "\n",
    "    isoform_start = 0\n",
    "    isoform_end = 185\n",
    "\n",
    "    pred_iso_all_cuts_from_cuts = np.sum(pred_cuts[:, isoform_start:isoform_end], axis=1)\n",
    "    score_all_cuts_from_cuts = np.log(pred_iso_all_cuts_from_cuts / (1. - pred_iso_all_cuts_from_cuts))\n",
    "    score_all_cuts = (score_from_iso + score_all_cuts_from_cuts) / 2.\n",
    "    \n",
    "    a[:, k] = score[:]\n",
    "    a_all_cuts[:, k] = score_all_cuts[:]\n",
    "\n",
    "a = a * m\n",
    "a = np.clip(a, -8., 8.)\n",
    "\n",
    "a_all_cuts = a_all_cuts * m\n",
    "a_all_cuts = np.clip(a_all_cuts, -8., 8.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dump prediction matrix\n",
    "\n",
    "np.save('apa_polyadb_data/' + model_name + '_native_scores_utr3', a)\n",
    "np.save('apa_polyadb_data/' + model_name + '_native_scores_utr3_all_cuts', a_all_cuts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
