{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from itertools import combinations\n",
    "from itertools import chain\n",
    "from collections import namedtuple\n",
    "import pickle\n",
    "import os.path\n",
    "\n",
    "import sys\n",
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Model\n",
    "from keras.layers import Bidirectional, Input, concatenate\n",
    "from keras.layers.core import Dense, Dropout, Flatten\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.pooling import MaxPooling1D, AveragePooling1D\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.layers.advanced_activations import PReLU\n",
    "from sklearn.metrics import average_precision_score, roc_auc_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Download DeepPASTA Models\n",
    "\n",
    "#!wget http://www.cs.ucr.edu/~aaref001/trained_models/tissue_specific_relatively_dominant/tissue_set_one/brain/DeepPASTA_relatively_brain_learned.hdf5\n",
    "#!wget http://www.cs.ucr.edu/~aaref001/trained_models/tissue_specific_relatively_dominant/tissue_set_one/kidney/DeepPASTA_relatively_kidney_learned.hdf5\n",
    "#!wget http://www.cs.ucr.edu/~aaref001/trained_models/tissue_specific_relatively_dominant/tissue_set_one/liver/DeepPASTA_relatively_liver_learned.hdf5\n",
    "#!wget http://www.cs.ucr.edu/~aaref001/trained_models/tissue_specific_relatively_dominant/tissue_set_one/maqc_brain1/DeepPASTA_relatively_maqc_brain1_learned.hdf5\n",
    "#!wget http://www.cs.ucr.edu/~aaref001/trained_models/tissue_specific_relatively_dominant/tissue_set_one/maqc_brain2/DeepPASTA_relatively_maqc_brain2_learned.hdf5\n",
    "#!wget http://www.cs.ucr.edu/~aaref001/trained_models/tissue_specific_relatively_dominant/tissue_set_one/maqc_UHR1/DeepPASTA_relatively_maqc_UHR1_learned.hdf5\n",
    "#!wget http://www.cs.ucr.edu/~aaref001/trained_models/tissue_specific_relatively_dominant/tissue_set_one/maqc_UHR2/DeepPASTA_relatively_maqc_UHR2_learned.hdf5\n",
    "#!wget http://www.cs.ucr.edu/~aaref001/trained_models/tissue_specific_relatively_dominant/tissue_set_one/muscle/DeepPASTA_relatively_muscle_learned.hdf5\n",
    "#!wget http://www.cs.ucr.edu/~aaref001/trained_models/tissue_specific_relatively_dominant/tissue_set_one/testis/DeepPASTA_relatively_testis_learned.hdf5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seqEncoder(rawSeqList):\n",
    "    if len(rawSeqList) != 0:\n",
    "        encodedSeq = np.zeros((len(rawSeqList), len(rawSeqList[0]), 5))\n",
    "        for i in range(len(rawSeqList)):\n",
    "            sequence = rawSeqList[i]\n",
    "            j = 0\n",
    "            for s in sequence:\n",
    "                if s == 'A' or s == 'a':\n",
    "                    encodedSeq[i][j] = [1,0,0,0,0]\n",
    "                elif s == 'T' or s == 't':\n",
    "                    encodedSeq[i][j] = [0,1,0,0,0]\n",
    "                elif s == 'C' or s == 'c':\n",
    "                    encodedSeq[i][j] = [0,0,1,0,0]\n",
    "                elif s == 'G' or s == 'g':\n",
    "                    encodedSeq[i][j] = [0,0,0,1,0]\n",
    "                elif s == 'N' or s == 'n':\n",
    "                    encodedSeq[i][j] = [0,0,0,0,1]\n",
    "                else:\n",
    "                    print>>sys.stderr, 'ERROR: Unwanted nucleotide: ' + s\n",
    "                j = j + 1\n",
    "        return encodedSeq\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def structEncoder(rawStructureList):\n",
    "    if len(rawStructureList) != 0:\n",
    "        encodedStructure = np.zeros((len(rawStructureList), len(rawStructureList[0]), 7))\n",
    "        for i in range(len(rawStructureList)):\n",
    "            structure = rawStructureList[i]\n",
    "            j = 0\n",
    "            for s in structure:\n",
    "                if s == 'U':\n",
    "                    encodedStructure[i][j] = [1,0,0,0,0,0,0]\n",
    "                elif s == 'E':\n",
    "                    encodedStructure[i][j] = [0,1,0,0,0,0,0]\n",
    "                elif s == 'L':\n",
    "                    encodedStructure[i][j] = [0,0,1,0,0,0,0]\n",
    "                elif s == 'R':\n",
    "                    encodedStructure[i][j] = [0,0,0,1,0,0,0]\n",
    "                elif s == 'H':\n",
    "                    encodedStructure[i][j] = [0,0,0,0,1,0,0]\n",
    "                elif s == 'M':\n",
    "                    encodedStructure[i][j] = [0,0,0,0,0,1,0]\n",
    "                elif s == 'I':\n",
    "                    encodedStructure[i][j] = [0,0,0,0,0,0,1]\n",
    "                else:\n",
    "                    print>>sys.stderr, 'Warning: Unwanted character ' + s\n",
    "                j = j + 1\n",
    "        return encodedStructure\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def sequenceModel(seqInput):\n",
    "    seqCov = Conv1D(filters=256,\n",
    "        kernel_size=8,\n",
    "        padding = \"valid\",\n",
    "        input_shape =(200, 5),\n",
    "        strides=1)(seqInput) \n",
    "\n",
    "    activa_conv = PReLU(alpha_initializer = 'zero', weights = None)(seqCov)\n",
    "\n",
    "    seqPool = MaxPooling1D(pool_size = 10, strides = 5)(activa_conv)\n",
    "    seqPoolDout = Dropout(rate = 0.2)(seqPool)\n",
    "\n",
    "    seqBiLstm = Bidirectional(LSTM(units = 128, return_sequences = True))(seqPoolDout)\n",
    "    seqBiLstmDout = Dropout(rate = 0.5)(seqBiLstm)\n",
    "    seqFlat = Flatten()(seqBiLstmDout)\n",
    "\n",
    "    seqDen1 = Dense(256, kernel_initializer='glorot_uniform', activation = 'relu')(seqFlat)\n",
    "    seqDout1 = Dropout(rate = 0.5)(seqDen1)\n",
    "\n",
    "    return seqDout1\n",
    "\n",
    "def combinedModel(seqInput, structInput):\n",
    "    layer_list = []\n",
    "\n",
    "    layer_list.append(sequenceModel(seqInput))\n",
    "\n",
    "    layer_list.append(structureModel(structInput))\n",
    "    merged_layer = concatenate(layer_list)\n",
    "\n",
    "    comDen1 = Dense(128, kernel_initializer='glorot_uniform', activation = 'relu')(merged_layer)\n",
    "    comDout1 = Dropout(rate = 0.5)(comDen1)\n",
    "\n",
    "\n",
    "    comDen2 = Dense(64, kernel_initializer='glorot_uniform', activation = 'relu')(comDout1)\n",
    "    comDout2 = Dropout(rate = 0.5)(comDen2)\n",
    "\n",
    "    comDen4 = Dense(1, kernel_initializer='glorot_uniform')(comDout2)\n",
    "\n",
    "    return comDen4\n",
    "\n",
    "\n",
    "def structureModel(structInput):\n",
    "    structCov = Conv1D(filters = 16,\n",
    "               kernel_size = 12,\n",
    "               padding = 'valid',\n",
    "               activation = 'relu',\n",
    "               strides = 1)(structInput)\n",
    "\n",
    "    structPool = AveragePooling1D(pool_size = 20, strides = 10)(structCov)\n",
    "    structPoolDout = Dropout(rate=0.2)(structPool)\n",
    "\n",
    "    structBiLstm = Bidirectional(LSTM(units = 8, return_sequences = True))(structPoolDout)\n",
    "    structBiLstmDout = Dropout(rate = 0.5)(structBiLstm)\n",
    "    structFlat = Flatten()(structBiLstmDout)\n",
    "\n",
    "    structDen1 = Dense(2, kernel_initializer='glorot_uniform')(structFlat)\n",
    "    structActivaDen1 = PReLU(alpha_initializer = 'zero', weights= None)(structDen1)\n",
    "    structDout1 = Dropout(rate=0.9)(structActivaDen1)\n",
    "\n",
    "    return structDout1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def get_predict_func(model_file) :\n",
    "    \n",
    "    # Building deep learning model \n",
    "    training_net = []\n",
    "    # deep learning sub-model for sequence\n",
    "    seqInput1 = Input(shape = (200, 5))\n",
    "    structInput1 = Input(shape = (200, 7))\n",
    "    comModel1 = combinedModel(seqInput1, structInput1)\n",
    "    training_net.append(comModel1)\n",
    "    # deep learning sub-model for structure\n",
    "    seqInput2 = Input(shape = (200, 5))\n",
    "    structInput2 = Input(shape = (200, 7))\n",
    "    comModel2 = combinedModel(seqInput2, structInput2)\n",
    "    training_net.append(comModel2)\n",
    "    merged_model = concatenate(training_net)\n",
    "\n",
    "    den1_1 = Dense(2, activation = 'softmax')(merged_model)\n",
    "\n",
    "    model = Model(inputs = [seqInput1,structInput1, seqInput2,structInput2], outputs = den1_1)\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    model.load_weights(model_file)\n",
    "    \n",
    "    def _predict(testingSequenceList1, testingSequenceList2, testingStructList1, testingStructList2) :\n",
    "        \n",
    "        encodedTesting1 = seqEncoder(testingSequenceList1)\n",
    "        encodedTesting2 = seqEncoder(testingSequenceList2)\n",
    "\n",
    "        encodedTestingStructure1 = structEncoder(testingStructList1)\n",
    "        encodedTestingStructure2 = structEncoder(testingStructList2)\n",
    "\n",
    "        testingData = []\n",
    "        testingData.append(encodedTesting1)\n",
    "        testingData.append(encodedTestingStructure1)\n",
    "        testingData.append(encodedTesting2)\n",
    "        testingData.append(encodedTestingStructure2)\n",
    "\n",
    "        preds = model.predict(testingData, batch_size = 100, verbose = 0)\n",
    "\n",
    "        return preds\n",
    "    \n",
    "    return _predict\n",
    "\n",
    "tissue_types = [\n",
    "    'brain',\n",
    "    'kidney',\n",
    "    'liver',\n",
    "    'maqc_brain1',\n",
    "    'maqc_brain2',\n",
    "    'maqc_UHR1',\n",
    "    'maqc_UHR2',\n",
    "    'muscle',\n",
    "    'testis',\n",
    "]\n",
    "\n",
    "model_files = [\"DeepPASTA_relatively_\" + tissue_type + \"_learned.hdf5\" for tissue_type in tissue_types]\n",
    "\n",
    "predict_funcs = [get_predict_func(model_file) for model_file in model_files]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load dataframe of sequences to predict APA for\n",
    "\n",
    "df = pd.read_csv('../PolyApredictors/apa_leslie_derti_apadb_pair_data_df_pair.csv', sep='\\t')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pad sequences to fit DeepPASTA input format\n",
    "\n",
    "df['seq_p'] = df['wide_seq_ext_prox'].str.slice(175-70, 175-70+205-5)\n",
    "df['seq_d'] = df['wide_seq_ext_dist'].str.slice(175-70, 175-70+205-5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting program ...\n",
      "Output from RNAshapes: temp_shapes1.txt\n",
      "Output filename: temp_shapes2.txt\n",
      "Starting program ...\n",
      "Number of suboptimal structures considered: 1\n",
      "Output from RNAshapes: temp_shapes2.txt\n",
      "Output filename: temp_shapes3.txt\n",
      "Starting program ...\n",
      "Number of structure: 1\n",
      "Output from RNAshapes to assign structure: temp_shapes3.txt\n",
      "Output file name: temp_shapes4_p.txt\n"
     ]
    }
   ],
   "source": [
    "#Generate RNA structures\n",
    "\n",
    "with open(\"test1_p.fa\", \"wt\") as temp_f :\n",
    "    i = 0\n",
    "    for _, row in df.iterrows() :\n",
    "        temp_f.write(\">seq\" + str(i) + \"\\n\" + row['seq_p'] + \"\\n\")\n",
    "        i += 1\n",
    "\n",
    "!./generating_secondary_structure_from_sequence/RNAshapes -f ./test1_p.fa -s -c 5 -t 1 -w 100 -W 100 -O 'D{%s\\n}' > temp_shapes1.txt\n",
    "!python2 ./generating_secondary_structure_from_sequence/combining_substructure.py -i temp_shapes1.txt -o temp_shapes2.txt\n",
    "!python2 ./generating_secondary_structure_from_sequence/filtering_number_of_ss.py -n 1 -i temp_shapes2.txt -o temp_shapes3.txt\n",
    "!python2 ./generating_secondary_structure_from_sequence/shape_assign_per_nucleotide.py -c 1 -i temp_shapes3.txt -o temp_shapes4_p.txt\n",
    "\n",
    "structs_prox_p = []\n",
    "with open(\"temp_shapes4_p.txt\", \"rt\") as temp_f :\n",
    "    i = 0\n",
    "    for line in temp_f.readlines() :\n",
    "        if i % 2 == 1 :\n",
    "            struct_prox = line.strip()\n",
    "            structs_prox_p.append(struct_prox)\n",
    "        i += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting program ...\n",
      "Output from RNAshapes: temp_shapes1.txt\n",
      "Output filename: temp_shapes2.txt\n",
      "Starting program ...\n",
      "Number of suboptimal structures considered: 1\n",
      "Output from RNAshapes: temp_shapes2.txt\n",
      "Output filename: temp_shapes3.txt\n",
      "Starting program ...\n",
      "Number of structure: 1\n",
      "Output from RNAshapes to assign structure: temp_shapes3.txt\n",
      "Output file name: temp_shapes4_d.txt\n"
     ]
    }
   ],
   "source": [
    "#Generate RNA structures\n",
    "\n",
    "with open(\"test1_d.fa\", \"wt\") as temp_f :\n",
    "    i = 0\n",
    "    for _, row in df.iterrows() :\n",
    "        temp_f.write(\">seq\" + str(i) + \"\\n\" + row['seq_d'] + \"\\n\")\n",
    "        i += 1\n",
    "\n",
    "!./generating_secondary_structure_from_sequence/RNAshapes -f ./test1_d.fa -s -c 5 -t 1 -w 100 -W 100 -O 'D{%s\\n}' > temp_shapes1.txt\n",
    "!python2 ./generating_secondary_structure_from_sequence/combining_substructure.py -i temp_shapes1.txt -o temp_shapes2.txt\n",
    "!python2 ./generating_secondary_structure_from_sequence/filtering_number_of_ss.py -n 1 -i temp_shapes2.txt -o temp_shapes3.txt\n",
    "!python2 ./generating_secondary_structure_from_sequence/shape_assign_per_nucleotide.py -c 1 -i temp_shapes3.txt -o temp_shapes4_d.txt\n",
    "\n",
    "structs_dist_d = []\n",
    "with open(\"temp_shapes4_d.txt\", \"rt\") as temp_f :\n",
    "    i = 0\n",
    "    for line in temp_f.readlines() :\n",
    "        if i % 2 == 1 :\n",
    "            struct_dist = line.strip()\n",
    "            structs_dist_d.append(struct_dist)\n",
    "        i += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Execute all tissue-specific APA predictors on each sequence\n",
    "\n",
    "testingSequenceList_p = [row['seq_p'] for _, row in df.iterrows()]\n",
    "testingSequenceList_d = [row['seq_d'] for _, row in df.iterrows()]\n",
    "testingStructList_p = structs_prox_p\n",
    "testingStructList_d = structs_dist_d\n",
    "\n",
    "y_pred_tissues = []\n",
    "for tissue_type_ix, tissue_type in enumerate(tissue_types) :\n",
    "    y_pred = predict_funcs[tissue_type_ix](testingSequenceList_p, testingSequenceList_d, testingStructList_p, testingStructList_d)[:, 0][:, None]\n",
    "    y_pred_tissues.append(y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate isoform log odds\n",
    "\n",
    "logodds_pred_tissues = []\n",
    "for tissue_type_ix, tissue_type in enumerate(tissue_types) :\n",
    "    logodds_pred = np.log(y_pred_tissues[tissue_type_ix] / (1. - y_pred_tissues[tissue_type_ix]))\n",
    "    \n",
    "    logodds_pred_tissues.append(logodds_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Store predictions in df\n",
    "\n",
    "for tissue_type_ix, tissue_type in enumerate(tissue_types) :\n",
    "    y_pred = y_pred_tissues[tissue_type_ix]\n",
    "    logodds_pred = logodds_pred_tissues[tissue_type_ix]\n",
    "    \n",
    "    df['iso_pred_' + tissue_type] = np.ravel(y_pred)\n",
    "    df['logodds_pred_' + tissue_type] = np.ravel(logodds_pred)\n",
    "\n",
    "df['usage_prox'] = np.mean(np.concatenate(y_pred_tissues, axis=1), axis=1)\n",
    "df['score_prox'] = np.mean(np.concatenate(logodds_pred_tissues, axis=1), axis=1)\n",
    "df['score_dist'] = 0.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "f = plt.figure()\n",
    "\n",
    "plt.hist(y_pred_tissues[0], bins=50)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Re-save prediction df\n",
    "\n",
    "df[['gene_id', 'seq_prox', 'seq_dist', 'usage_prox', 'score_prox', 'score_dist']].to_csv(\"apa_leslie_derti_apadb_pair_data_df_pair_deeppasta.csv\", sep='\\t', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p36)",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
