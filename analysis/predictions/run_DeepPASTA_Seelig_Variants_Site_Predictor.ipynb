{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from itertools import combinations\n",
    "from itertools import chain\n",
    "from collections import namedtuple\n",
    "import pickle\n",
    "import os.path\n",
    "\n",
    "import sys\n",
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Model\n",
    "from keras.layers import Bidirectional, Input, concatenate, add\n",
    "from keras.layers.core import Dense, Dropout, Flatten\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.pooling import MaxPooling1D, AveragePooling1D\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.layers.advanced_activations import PReLU\n",
    "from sklearn.metrics import average_precision_score, roc_auc_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oneHotEncodingForSeq(rawSeqList):\n",
    "    if len(rawSeqList) != 0:\n",
    "        encodedSeq = np.zeros((len(rawSeqList), len(rawSeqList[0]), 5))\n",
    "        for i in range(len(rawSeqList)):\n",
    "            sequence = rawSeqList[i]\n",
    "            j = 0\n",
    "            for s in sequence:\n",
    "                if s == 'A' or s == 'a':\n",
    "                    encodedSeq[i][j] = [1,0,0,0,0]\n",
    "                elif s == 'T' or s == 't':\n",
    "                    encodedSeq[i][j] = [0,1,0,0,0]\n",
    "                elif s == 'C' or s == 'c':\n",
    "                    encodedSeq[i][j] = [0,0,1,0,0]\n",
    "                elif s == 'G' or s == 'g':\n",
    "                    encodedSeq[i][j] = [0,0,0,1,0]\n",
    "                elif s == 'N' or s == 'n':\n",
    "                    encodedSeq[i][j] = [0,0,0,0,1]\n",
    "                j = j + 1\n",
    "        return encodedSeq\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def oneHotEncodingForSS(rawStructureList):\n",
    "    if len(rawStructureList) != 0:\n",
    "        encodedStructure = np.zeros((len(rawStructureList), len(rawStructureList[0]), 7))\n",
    "        for i in range(len(rawStructureList)):\n",
    "            structure = rawStructureList[i]\n",
    "            j = 0\n",
    "            for s in structure:\n",
    "                if s == 'U':\n",
    "                    encodedStructure[i][j] = [1,0,0,0,0,0,0]\n",
    "                elif s == 'E':\n",
    "                    encodedStructure[i][j] = [0,1,0,0,0,0,0]\n",
    "                elif s == 'L':\n",
    "                    encodedStructure[i][j] = [0,0,1,0,0,0,0]\n",
    "                elif s == 'R':\n",
    "                    encodedStructure[i][j] = [0,0,0,1,0,0,0]\n",
    "                elif s == 'H':\n",
    "                    encodedStructure[i][j] = [0,0,0,0,1,0,0]\n",
    "                elif s == 'M':\n",
    "                    encodedStructure[i][j] = [0,0,0,0,0,1,0]\n",
    "                elif s == 'I':\n",
    "                    encodedStructure[i][j] = [0,0,0,0,0,0,1]\n",
    "                j = j + 1\n",
    "        return encodedStructure\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def matchingLabelBetweenSeqAndStructure(seqLabelList, structureLabelList, kindOfData):\n",
    "    print>>sys.stderr, 'Checking label similarity between sequence and structure of ' + kindOfData + ' data'\n",
    "    for index in range(len(seqLabelList)):\n",
    "        if seqLabelList[index] != structureLabelList[index]:\n",
    "            print>>sys.stderr, 'ERROR: label mismatch between sequence and structure'\n",
    "\n",
    "def sequenceModel(seqInput):\n",
    "    seqCov = Conv1D(filters=512,\n",
    "        kernel_size=8,\n",
    "        padding = \"valid\",\n",
    "        input_shape =(200, 5),\n",
    "        activation=\"relu\",\n",
    "        strides=1)(seqInput) \n",
    "\n",
    "    seqPool = MaxPooling1D(pool_size = 3, strides = 3)(seqCov)\n",
    "    seqDout1 = Dropout(rate = 0.7)(seqPool)\n",
    "    seqBiLstm = Bidirectional(LSTM(units = 128, return_sequences = True))(seqDout1)\n",
    "    seqDout2 = Dropout(rate = 0.7)(seqBiLstm)\n",
    "    seqFlat = Flatten()(seqDout2)\n",
    "    seqDen2 = Dense(256, kernel_initializer='glorot_uniform', activation = 'relu')(seqFlat)\n",
    "    seqDout4 = Dropout(rate = 0.7)(seqDen2)\n",
    "\n",
    "    return seqDout4\n",
    "\n",
    "def structureSubModel(ssInput):\n",
    "    ssConv = Conv1D(filters=256,\n",
    "                    kernel_size=12,\n",
    "            padding = \"valid\",\n",
    "            activation=\"relu\",\n",
    "            strides=1)(ssInput)\n",
    "    ssPool = AveragePooling1D(pool_size = 5, strides = 5)(ssConv)\n",
    "    ssDout1 = Dropout(rate=0.7)(ssPool)\n",
    "    seqBiLstm = Bidirectional(LSTM(units = 128, return_sequences = True))(ssDout1)\n",
    "    seqDout2 = Dropout(rate = 0.7)(seqBiLstm)\n",
    "    ssFlat = Flatten()(seqDout2)\n",
    "    ssDen1 = Dense(256, kernel_initializer='glorot_uniform', activation = 'relu')(ssFlat)\n",
    "    ssDout2 = Dropout(rate=0.7)(ssDen1)\n",
    "\n",
    "    return ssDout2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_predict_func() :\n",
    "    \n",
    "    structureSeqLength = 200\n",
    "    \n",
    "    # Building deep learning model\n",
    "    training_net = []\n",
    "    # deep learning sub-model for sequence\n",
    "    seqInput = Input(shape = (200, 5))\n",
    "    seqModel = sequenceModel(seqInput)\n",
    "    training_net.append(seqModel)\n",
    "\n",
    "    # deep learning sub-model for structure\n",
    "    ss_training_net = []\n",
    "    ssInput1 = Input(shape = (structureSeqLength, 7))\n",
    "    ssInput2 = Input(shape = (structureSeqLength, 7))\n",
    "    ssInput3 = Input(shape = (structureSeqLength, 7))\n",
    "\n",
    "    ss_training_net.append(structureSubModel(ssInput1))\n",
    "    ss_training_net.append(structureSubModel(ssInput2))\n",
    "    ss_training_net.append(structureSubModel(ssInput3))\n",
    "\n",
    "    ss_merged_model = add(ss_training_net)\n",
    "    ss_den1 = Dense(256, kernel_initializer = 'glorot_uniform', activation = 'relu')(ss_merged_model)\n",
    "    ss_dout1 = Dropout(rate = 0.7)(ss_den1)\n",
    "    training_net.append(ss_dout1)\n",
    "    merged_model = concatenate(training_net)\n",
    "\n",
    "    den1 = Dense(256, kernel_initializer = 'glorot_uniform', activation = 'relu')(merged_model)\n",
    "    dout1 = Dropout(rate = 0.7)(den1)\n",
    "\n",
    "    den2 = Dense(128, kernel_initializer = 'glorot_uniform', activation = 'relu')(dout1)\n",
    "    dout2 = Dropout(rate = 0.7)(den2)\n",
    "    den3 = Dense(64, activation = 'relu')(dout2)\n",
    "    den4 = Dense(1, activation = 'sigmoid')(den3)\n",
    "    model = Model(inputs = [seqInput, ssInput1, ssInput2, ssInput3], outputs = den4)\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', optimizer='nadam', metrics=['accuracy'])\n",
    "\n",
    "    model.load_weights('DeepPASTA_polyA_site_learned.hdf5')\n",
    "    \n",
    "    def _predict(testingSequenceList, testingStructureList1, testingStructureList2, testingStructureList3) :\n",
    "        \n",
    "        encodedTestingSeq = oneHotEncodingForSeq(testingSequenceList)\n",
    "        encodedTestingStructure1 = oneHotEncodingForSS(testingStructureList1)\n",
    "        encodedTestingStructure2 = oneHotEncodingForSS(testingStructureList2)\n",
    "        encodedTestingStructure3 = oneHotEncodingForSS(testingStructureList3)\n",
    "\n",
    "        testingData = []\n",
    "        testingData.append(encodedTestingSeq)\n",
    "        testingData.append(encodedTestingStructure1)\n",
    "        testingData.append(encodedTestingStructure2)\n",
    "        testingData.append(encodedTestingStructure3)\n",
    "\n",
    "        preds = model.predict(testingData, batch_size = 2042, verbose = 0)\n",
    "\n",
    "        return preds\n",
    "    \n",
    "    return _predict\n",
    "\n",
    "predict_func = get_predict_func()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load dataframe of sequences to predict APA for\n",
    "\n",
    "df = pd.read_csv(\"aparent_theano_legacy_30_31_34_pasaligned_predictions_master_seq_array_df.csv\", sep='\\t')[['master_seq']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pad sequences to fit DeepPASTA input format\n",
    "\n",
    "up_pad = \"CAAGTCTTGATACACGACGCTCTTCCGATCT\"\n",
    "dn_pad = \"GGAGC\"\n",
    "\n",
    "df['seq'] = up_pad + df['master_seq'] + dn_pad\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting program ...\n",
      "Output from RNAshapes: temp_shapes1_site_pred.txt\n",
      "Output filename: temp_shapes2_site_pred.txt\n",
      "Starting program ...\n",
      "Number of suboptimal structures considered: 3\n",
      "Output from RNAshapes: temp_shapes2_site_pred.txt\n",
      "Output filename: temp_shapes3_site_pred.txt\n",
      "Starting program ...\n",
      "Number of structure: 3\n",
      "Output from RNAshapes to assign structure: temp_shapes3_site_pred.txt\n",
      "Output file name: temp_shapes4_site_pred.txt\n"
     ]
    }
   ],
   "source": [
    "#Generate RNA structures\n",
    "\n",
    "with open(\"test1_site_pred.fa\", \"wt\") as temp_f :\n",
    "    i = 0\n",
    "    for _, row in df.iterrows() :\n",
    "        temp_f.write(\">seq\" + str(i) + \"\\n\" + row['seq'] + \"\\n\")\n",
    "        i += 1\n",
    "\n",
    "!./generating_secondary_structure_from_sequence/RNAshapes -f ./test1_site_pred.fa -s -c 5 -t 1 -w 100 -W 100 -O 'D{%s\\n}' > temp_shapes1_site_pred.txt\n",
    "!python2 ./generating_secondary_structure_from_sequence/combining_substructure.py -i temp_shapes1_site_pred.txt -o temp_shapes2_site_pred.txt\n",
    "!python2 ./generating_secondary_structure_from_sequence/filtering_number_of_ss.py -n 3 -i temp_shapes2_site_pred.txt -o temp_shapes3_site_pred.txt\n",
    "!python2 ./generating_secondary_structure_from_sequence/shape_assign_per_nucleotide.py -c 3 -i temp_shapes3_site_pred.txt -o temp_shapes4_site_pred.txt\n",
    "\n",
    "structs_prox_1 = []\n",
    "structs_prox_2 = []\n",
    "structs_prox_3 = []\n",
    "with open(\"temp_shapes4_site_pred.txt\", \"rt\") as temp_f :\n",
    "    i = 0\n",
    "    for line in temp_f.readlines() :\n",
    "        if i % 4 == 1 :\n",
    "            struct_prox = line.strip()\n",
    "            structs_prox_1.append(struct_prox)\n",
    "        if i % 4 == 2 :\n",
    "            struct_prox = line.strip()\n",
    "            structs_prox_2.append(struct_prox)\n",
    "        if i % 4 == 3 :\n",
    "            struct_prox = line.strip()\n",
    "            structs_prox_3.append(struct_prox)\n",
    "        i += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Execute all pA site prediction model\n",
    "\n",
    "testingSequenceList = [row['seq'] for _, row in df.iterrows()]\n",
    "testingStructList1 = structs_prox_1\n",
    "testingStructList2 = structs_prox_2\n",
    "testingStructList3 = structs_prox_3\n",
    "\n",
    "y_pred = predict_func(testingSequenceList, testingStructList1, testingStructList2, testingStructList3)[:, 0][:, None]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate isoform log odds\n",
    "\n",
    "logodds_pred = np.log(y_pred / (1. - y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Store predictions in df\n",
    "\n",
    "df['iso_pred'] = y_pred[:, 0]\n",
    "df['logodds_pred'] = logodds_pred[:, 0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Re-save prediction df\n",
    "\n",
    "df.to_csv(\"aparent_theano_legacy_30_31_34_pasaligned_predictions_master_seq_array_df_deeppasta_site_predictor.csv\", sep='\\t', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p36)",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
