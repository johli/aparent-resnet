{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.models import Sequential, Model, load_model\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "import scipy.sparse as sp\n",
    "import scipy.io as spio\n",
    "\n",
    "import isolearn.io as isoio\n",
    "import isolearn.keras as iso\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jlinder2/anaconda3/envs/tensorflow/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2785: DtypeWarning: Columns (200,201,203,207,208,210) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "#Load sequence data\n",
    "\n",
    "df = pd.read_csv('../../../aparent/data/polyadb_features_pas_3_utr3_isoforms.csv', sep='\\t')\n",
    "\n",
    "save_dict = np.load(\"../../../aparent/data/polyadb_features_pas_3_utr3_isoforms_no_x.npz\")\n",
    "m, l = save_dict['m'], save_dict['l']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/jlinder2/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/jlinder2/anaconda3/envs/tensorflow/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jlinder2/anaconda3/envs/tensorflow/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n"
     ]
    }
   ],
   "source": [
    "#Load APARENT Resnet\n",
    "\n",
    "model_name = 'aparent_all_libs_resnet_no_clinvar_wt_ep_5'\n",
    "\n",
    "save_dir = os.path.join(os.getcwd(), '../../../aparent-resnet/saved_models')\n",
    "model_path = os.path.join(save_dir, model_name + '.h5')\n",
    "\n",
    "aparent_model = load_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting for PAS #0...\n",
      "10432/10432 [==============================] - 85s 8ms/step\n",
      "Predicting for PAS #1...\n",
      "10432/10432 [==============================] - 105s 10ms/step\n",
      "Predicting for PAS #2...\n",
      "10432/10432 [==============================] - 77s 7ms/step\n",
      "Predicting for PAS #3...\n",
      "10432/10432 [==============================] - 79s 8ms/step\n",
      "Predicting for PAS #4...\n",
      "10432/10432 [==============================] - 74s 7ms/step\n",
      "Predicting for PAS #5...\n",
      "10432/10432 [==============================] - 73s 7ms/step\n",
      "Predicting for PAS #6...\n",
      "10432/10432 [==============================] - 73s 7ms/step\n",
      "Predicting for PAS #7...\n",
      "10432/10432 [==============================] - 73s 7ms/step\n",
      "Predicting for PAS #8...\n",
      "10432/10432 [==============================] - 75s 7ms/step\n",
      "Predicting for PAS #9...\n",
      "10432/10432 [==============================] - 75s 7ms/step\n",
      "Predicting for PAS #10...\n",
      "10432/10432 [==============================] - 72s 7ms/step\n",
      "Predicting for PAS #11...\n",
      "10432/10432 [==============================] - 73s 7ms/step\n",
      "Predicting for PAS #12...\n",
      "10432/10432 [==============================] - 73s 7ms/step\n",
      "Predicting for PAS #13...\n",
      "10432/10432 [==============================] - 73s 7ms/step\n",
      "Predicting for PAS #14...\n",
      "10432/10432 [==============================] - 73s 7ms/step\n",
      "Predicting for PAS #15...\n",
      "10432/10432 [==============================] - 73s 7ms/step\n",
      "Predicting for PAS #16...\n",
      "10432/10432 [==============================] - 73s 7ms/step\n",
      "Predicting for PAS #17...\n",
      "10432/10432 [==============================] - 73s 7ms/step\n",
      "Predicting for PAS #18...\n",
      "10432/10432 [==============================] - 73s 7ms/step\n",
      "Predicting for PAS #19...\n",
      "10432/10432 [==============================] - 74s 7ms/step\n",
      "Predicting for PAS #20...\n",
      "10432/10432 [==============================] - 76s 7ms/step\n",
      "Predicting for PAS #21...\n",
      "10432/10432 [==============================] - 73s 7ms/step\n",
      "Predicting for PAS #22...\n",
      "10432/10432 [==============================] - 73s 7ms/step\n",
      "Predicting for PAS #23...\n",
      "10432/10432 [==============================] - 73s 7ms/step\n",
      "Predicting for PAS #24...\n",
      "10432/10432 [==============================] - 73s 7ms/step\n",
      "Predicting for PAS #25...\n",
      "10432/10432 [==============================] - 73s 7ms/step\n",
      "Predicting for PAS #26...\n",
      "10432/10432 [==============================] - 73s 7ms/step\n",
      "Predicting for PAS #27...\n",
      "10432/10432 [==============================] - 74s 7ms/step\n",
      "Predicting for PAS #28...\n",
      "10432/10432 [==============================] - 73s 7ms/step\n",
      "Predicting for PAS #29...\n",
      "10432/10432 [==============================] - 77s 7ms/step\n"
     ]
    }
   ],
   "source": [
    "#Score all sequences with APARENT (use sum of cuts to capture OR-like logic)\n",
    "\n",
    "max_n_pas = 30\n",
    "\n",
    "encoder = iso.OneHotEncoder(205)\n",
    "\n",
    "a = np.zeros((len(df), max_n_pas))\n",
    "a_all_cuts = np.zeros((len(df), max_n_pas))\n",
    "\n",
    "for k in range(max_n_pas) :\n",
    "    \n",
    "    print(\"Predicting for PAS #\" + str(k) + \"...\")\n",
    "    \n",
    "    df.loc[df['wide_seq_ext_' + str(k)].isnull(), 'wide_seq_ext_' + str(k)] = 'X' * 205\n",
    "    \n",
    "    onehots = np.concatenate([encoder.encode(row['wide_seq_ext_' + str(k)][175-70:175-70+205])[None, None, :, :] for _, row in df.iterrows()], axis=0)\n",
    "    \n",
    "    fake_lib = np.zeros((onehots.shape[0], 13))\n",
    "    fake_lib[:, 11] = 1.\n",
    "    \n",
    "    #Pad\n",
    "    n_pad = 32 - onehots.shape[0] % 32 if onehots.shape[0] % 32 != 0 else 0\n",
    "\n",
    "    fake_lib = np.concatenate([fake_lib, np.zeros((n_pad, 13))], axis=0)\n",
    "    onehots = np.concatenate([onehots, np.zeros((n_pad, 1, 205, 4))], axis=0)\n",
    "    \n",
    "    _, pred_cuts = aparent_model.predict(x=[onehots, fake_lib], batch_size=32, verbose=1)\n",
    "    \n",
    "    if n_pad > 0 :\n",
    "        pred_cuts = pred_cuts[:-n_pad, :]\n",
    "    \n",
    "    isoform_start = 77\n",
    "    isoform_end = 127\n",
    "\n",
    "    pred_iso = np.sum(pred_cuts[:, isoform_start:isoform_end], axis=1)\n",
    "    score = np.log(pred_iso / (1. - pred_iso))\n",
    "\n",
    "    isoform_start = 0\n",
    "    isoform_end = 205\n",
    "\n",
    "    pred_iso_all_cuts = np.sum(pred_cuts[:, isoform_start:isoform_end], axis=1)\n",
    "    score_all_cuts = np.log(pred_iso_all_cuts / (1. - pred_iso_all_cuts))\n",
    "\n",
    "    a[:, k] = score[:]\n",
    "    a_all_cuts[:, k] = score_all_cuts[:]\n",
    "\n",
    "a = a * m\n",
    "a = np.clip(a, -10., 10.)\n",
    "\n",
    "a_all_cuts = a_all_cuts * m\n",
    "a_all_cuts = np.clip(a_all_cuts, -10., 10.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dump prediction matrix\n",
    "\n",
    "np.save('apa_polyadb_data/' + model_name + '_native_scores_utr3_isoforms', a)\n",
    "np.save('apa_polyadb_data/' + model_name + '_native_scores_utr3_isoform_all_cuts', a_all_cuts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
