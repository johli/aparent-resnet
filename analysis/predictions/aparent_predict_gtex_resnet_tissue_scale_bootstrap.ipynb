{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.models import Sequential, Model, load_model\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "import scipy.sparse as sp\n",
    "import scipy.io as spio\n",
    "\n",
    "import isolearn.io as isoio\n",
    "import isolearn.keras as iso\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load sequence data\n",
    "\n",
    "df = pd.read_csv('../../data/prepared_data/apa_gtex_data/polyadb_merged_lead_SNPs.csv', sep='\\t')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create data features\n",
    "\n",
    "encoder = iso.OneHotEncoder(205)\n",
    "\n",
    "l_fake = np.zeros((len(df), 13))\n",
    "l_fake[:, 11] = 1.\n",
    "\n",
    "ref_onehots = np.concatenate([encoder.encode(row['wide_seq_ext'][175-70:175-70+205])[None, None, :, :] for _, row in df.iterrows()], axis=0)\n",
    "var_onehots = np.concatenate([encoder.encode(row['wide_seq_ext_var'][175-70:175-70+205])[None, None, :, :] for _, row in df.iterrows()], axis=0)\n",
    "\n",
    "#Pad\n",
    "n_pad = 32 - len(df) % 32 if len(df) % 32 != 0 else 0\n",
    "\n",
    "l_fake = np.concatenate([l_fake, np.zeros((n_pad, 13))], axis=0)\n",
    "ref_onehots = np.concatenate([ref_onehots, np.zeros((n_pad, 1, 205, 4))], axis=0)\n",
    "var_onehots = np.concatenate([var_onehots, np.zeros((n_pad, 1, 205, 4))], axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/jlinder2/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/jlinder2/anaconda3/envs/tensorflow/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jlinder2/anaconda3/envs/tensorflow/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n"
     ]
    }
   ],
   "source": [
    "#Load APARENT Resnet\n",
    "\n",
    "model_name = 'aparent_all_libs_resnet_no_clinvar_wt_ep_5'\n",
    "\n",
    "save_dir = os.path.join(os.getcwd(), '../../../aparent-resnet/saved_models')\n",
    "model_path = os.path.join(save_dir, model_name + '.h5')\n",
    "\n",
    "aparent_model = load_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5952/5952 [==============================] - 41s 7ms/step\n",
      "5952/5952 [==============================] - 41s 7ms/step\n"
     ]
    }
   ],
   "source": [
    "#Predict\n",
    "\n",
    "_, ref_cut_pred = aparent_model.predict(x=[ref_onehots, l_fake], batch_size=32, verbose=True)\n",
    "_, var_cut_pred = aparent_model.predict(x=[var_onehots, l_fake], batch_size=32, verbose=True)\n",
    "\n",
    "#Calculate isoform logits\n",
    "if n_pad > 0 :\n",
    "    ref_cut_pred = ref_cut_pred[:-n_pad, :]\n",
    "    var_cut_pred = var_cut_pred[:-n_pad, :]\n",
    "\n",
    "isoform_start = 0\n",
    "isoform_end = 205\n",
    "\n",
    "ref_iso_pred = np.sum(ref_cut_pred[:, isoform_start:isoform_end], axis=1)\n",
    "var_iso_pred = np.sum(var_cut_pred[:, isoform_start:isoform_end], axis=1)\n",
    "\n",
    "delta_logodds = np.log(var_iso_pred / (1. - var_iso_pred)) - np.log(ref_iso_pred / (1. - ref_iso_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting using model 0...\n",
      "5952/5952 [==============================] - 3s 544us/step\n",
      "5952/5952 [==============================] - 3s 504us/step\n",
      "Predicting using model 1...\n",
      "5952/5952 [==============================] - 3s 513us/step\n",
      "5952/5952 [==============================] - 3s 491us/step\n",
      "Predicting using model 2...\n",
      "5952/5952 [==============================] - 3s 520us/step\n",
      "5952/5952 [==============================] - 3s 480us/step\n",
      "Predicting using model 3...\n",
      "5952/5952 [==============================] - 4s 607us/step\n",
      "5952/5952 [==============================] - 3s 537us/step\n",
      "Predicting using model 4...\n",
      "5952/5952 [==============================] - 4s 614us/step\n",
      "5952/5952 [==============================] - 3s 548us/step\n",
      "Predicting using model 5...\n",
      "5952/5952 [==============================] - 3s 546us/step\n",
      "5952/5952 [==============================] - 3s 535us/step\n",
      "Predicting using model 6...\n",
      "5952/5952 [==============================] - 4s 601us/step\n",
      "5952/5952 [==============================] - 3s 549us/step\n",
      "Predicting using model 7...\n",
      "5952/5952 [==============================] - 3s 574us/step\n",
      "5952/5952 [==============================] - 3s 538us/step\n",
      "Predicting using model 8...\n",
      "5952/5952 [==============================] - 3s 580us/step\n",
      "5952/5952 [==============================] - 3s 550us/step\n",
      "Predicting using model 9...\n",
      "5952/5952 [==============================] - 3s 576us/step\n",
      "5952/5952 [==============================] - 3s 526us/step\n"
     ]
    }
   ],
   "source": [
    "#Load Tissue scaler and predict variant effects\n",
    "import keras.backend as K\n",
    "\n",
    "model_name = \"human_convnet_16_16_no_dense_linear_leslie_hek293_brain_all_cuts_retry_ensemble\"\n",
    "\n",
    "n_bootstraps = 10\n",
    "\n",
    "save_dir = '../../../aparent-resnet/saved_models'\n",
    "\n",
    "ref_tissue_scores = []\n",
    "var_tissue_scores = []\n",
    "\n",
    "for bootstrap_ix in range(n_bootstraps) :\n",
    "    \n",
    "    #Clear keras session\n",
    "    K.clear_session()\n",
    "    \n",
    "    print(\"Predicting using model \" + str(bootstrap_ix) + \"...\")\n",
    "    \n",
    "    #Load model(s)\n",
    "    if not os.path.isdir(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "\n",
    "    model_path = os.path.join(save_dir, model_name + '_' + str(bootstrap_ix) + '_pas_model' + '.h5')\n",
    "    tissue_model = load_model(model_path)\n",
    "    \n",
    "    #Predict\n",
    "    ref_tissue_score = tissue_model.predict(x=[np.tile(ref_onehots[:, None, ...], (1, 10, 1, 1, 1))], batch_size=32, verbose=True)\n",
    "    var_tissue_score = tissue_model.predict(x=[np.tile(var_onehots[:, None, ...], (1, 10, 1, 1, 1))], batch_size=32, verbose=True)\n",
    "\n",
    "    ref_tissue_score = ref_tissue_score[:, 0, :]\n",
    "    var_tissue_score = var_tissue_score[:, 0, :]\n",
    "\n",
    "    #Calculate isoform delta tissue logits\n",
    "    if n_pad > 0 :\n",
    "        ref_tissue_score = ref_tissue_score[:-n_pad, :]\n",
    "        var_tissue_score = var_tissue_score[:-n_pad, :]\n",
    "    \n",
    "    ref_tissue_scores.append(ref_tissue_score[None, ...])\n",
    "    var_tissue_scores.append(var_tissue_score[None, ...])\n",
    "\n",
    "ref_tissue_score = np.mean(np.concatenate(ref_tissue_scores, axis=0), axis=0)\n",
    "var_tissue_score = np.mean(np.concatenate(var_tissue_scores, axis=0), axis=0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ref_delta_tissue_score = ref_tissue_score[:, 1] - ref_tissue_score[:, 0]\n",
    "var_delta_tissue_score = var_tissue_score[:, 1] - var_tissue_score[:, 0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Copy the dataframe and store isoform predictions\n",
    "\n",
    "pred_df = df.copy().reset_index(drop=True)\n",
    "\n",
    "pred_df['delta_isoform_logodds'] = delta_logodds\n",
    "pred_df['ref_delta_tissue_score'] = ref_delta_tissue_score\n",
    "pred_df['var_delta_tissue_score'] = var_delta_tissue_score\n",
    "\n",
    "pred_df['ref_tissue_score_1'] = ref_tissue_score[:, 0]\n",
    "pred_df['ref_tissue_score_2'] = ref_tissue_score[:, 1]\n",
    "pred_df['var_tissue_score_1'] = var_tissue_score[:, 0]\n",
    "pred_df['var_tissue_score_2'] = var_tissue_score[:, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dump prediction dataframe and cut probability matrix\n",
    "\n",
    "isoio.dump({'pred_df' : pred_df}, 'apa_gtex_data/' + model_name + '_predictions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
